{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c146f4-e06c-4b57-a9dd-8f14de412180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a5beead-85b9-4a12-84e3-d4a2de9d7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#压缩数据内存#\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1ed5bf-a807-4312-a084-2db69cf22471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1796.90 MB\n",
      "Memory usage after optimization is: 488.64 MB\n",
      "Decreased by 72.8%\n",
      "Memory usage of dataframe is 1.42 MB\n",
      "Memory usage after optimization is: 0.41 MB\n",
      "Decreased by 70.8%\n",
      "Memory usage of dataframe is 526.70 MB\n",
      "Memory usage after optimization is: 143.23 MB\n",
      "Decreased by 72.8%\n",
      "(61866, 3807)\n",
      "(61866, 3)\n",
      "(18134, 3807)\n"
     ]
    }
   ],
   "source": [
    "#加载数据#\n",
    "train = import_data('C:/input/train_data.csv')\n",
    "target = import_data('C:/input/train_target.csv')\n",
    "test = import_data('C:/input/test_data.csv')\n",
    "print(train.shape)\n",
    "print(target.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d19ecccd-a143-4eb4-b488-ac87e9d18d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61866, 3807)\n",
      "(18134, 3807)\n",
      "(80000, 3807)\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train,test],axis = 0) # train，test索引上连接\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9cb830f-6fcf-4f50-a563-6e18ba00d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_test = test['idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed033d06-2682-4d7d-bb30-68572cdba4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X2255    100.00000\n",
      "X867     100.00000\n",
      "X823     100.00000\n",
      "X824     100.00000\n",
      "X825     100.00000\n",
      "           ...    \n",
      "X1937     40.89250\n",
      "X1253     40.82875\n",
      "X842      40.82875\n",
      "X706      40.82875\n",
      "X1946     40.18125\n",
      "Length: 2419, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data.isnull().sum(axis=0).sort_values(ascending = False) #查看各个特征缺失情况#\n",
    "missing_percentage = data.isnull().mean() * 100\n",
    "features_missing_more_than = missing_percentage[missing_percentage > 40]\n",
    "sorted_missing_features = features_missing_more_than.sort_values(ascending=False)\n",
    "print(sorted_missing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e73def-9cb8-46de-8158-d9958485953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_missing_more_than = sorted_missing_features.index.tolist()\n",
    "data = data.drop(features_missing_more_than,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bf33c71-f44c-47b0-ad4f-1ab1af927d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#拆分训练集和测试集#\n",
    "n_train = len(train)\n",
    "n_test = len(test)\n",
    "df_train = data.head(n_train)\n",
    "df_test = data.tail(n_test)\n",
    "df_train = df_train.drop('idx',axis = 1)\n",
    "df_test = df_test.drop('idx',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c47a7e2-a73d-4092-9283-9ae9763643c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = target['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48d5462b-071f-4cf7-b2bb-209eb9cc87d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=5 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=5 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 106414\n",
      "[LightGBM] [Info] Number of data points in the train set: 49492, number of used features: 1387\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=5 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=0.8 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Start training from score 0.183302\n",
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\tvalid_0's auc: 0.670399\n",
      "[200]\tvalid_0's auc: 0.679759\n",
      "[300]\tvalid_0's auc: 0.684507\n",
      "[400]\tvalid_0's auc: 0.686781\n",
      "[500]\tvalid_0's auc: 0.688364\n",
      "[600]\tvalid_0's auc: 0.689535\n",
      "[700]\tvalid_0's auc: 0.690475\n",
      "[800]\tvalid_0's auc: 0.691207\n",
      "[900]\tvalid_0's auc: 0.691808\n",
      "[1000]\tvalid_0's auc: 0.691998\n",
      "[1100]\tvalid_0's auc: 0.692606\n",
      "[1200]\tvalid_0's auc: 0.692645\n",
      "[1300]\tvalid_0's auc: 0.69279\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m valid_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_test, label\u001b[38;5;241m=\u001b[39my_test)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m     52\u001b[0m     params,\n\u001b[0;32m     53\u001b[0m     train_data,\n\u001b[0;32m     54\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4000\u001b[39m,  \u001b[38;5;66;03m# 使用000作为最大迭代次数\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39m[valid_data],\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks  \u001b[38;5;66;03m# 使用callbacks参数替代early_stopping_rounds和verbose_eval\u001b[39;00m\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# 预测验证集\u001b[39;00m\n\u001b[0;32m     60\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test, num_iteration\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mbest_iteration)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\lightgbm\\basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4135\u001b[0m _safe_call(\n\u001b[1;32m-> 4136\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[0;32m   4137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[0;32m   4138\u001b[0m         ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished),\n\u001b[0;32m   4139\u001b[0m     )\n\u001b[0;32m   4140\u001b[0m )\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 假设 df_train 是训练数据集，label 是目标变量\n",
    "# df_train = pd.DataFrame(...)  # 你的训练数据集\n",
    "# label = pd.Series(...)  # 你的目标变量\n",
    "# df_test = pd.DataFrame(...)  # 你的测试数据集\n",
    "# idx_test = pd.Series(...)  # 测试集的索引\n",
    "\n",
    "params = {\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 30,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.01,\n",
    "    'n_estimators':1500,\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq': 5,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'reg_alpha': 1.5,\n",
    "    'reg_lambda': 1.5,\n",
    "    'min_data_in_leaf':60,\n",
    "    'bagging_freq': 1,\n",
    "    'importance_type': 'gain'\n",
    "}\n",
    "\n",
    "# 初始化5折交叉验证生成器\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=3407)\n",
    "\n",
    "auc_list = []\n",
    "pred_list = []\n",
    "\n",
    "# 定义早停和日志记录的回调函数\n",
    "callbacks = [\n",
    "    lgb.early_stopping(stopping_rounds=400, first_metric_only=True, verbose=True),\n",
    "    lgb.log_evaluation(period=100)\n",
    "]\n",
    "\n",
    "for train_index, test_index in skf.split(df_train, label):\n",
    "    X_train, X_test = df_train.iloc[train_index], df_train.iloc[test_index]\n",
    "    y_train, y_test = label.iloc[train_index], label.iloc[test_index]\n",
    "    \n",
    "    # 创建LightGBM数据集\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_test, label=y_test)\n",
    "    \n",
    "    # 训练模型\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=4000,  # 使用000作为最大迭代次数\n",
    "        valid_sets=[valid_data],\n",
    "        callbacks=callbacks  # 使用callbacks参数替代early_stopping_rounds和verbose_eval\n",
    "    )\n",
    "    \n",
    "    # 预测验证集\n",
    "    pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "    auc = roc_auc_score(y_test, pred)\n",
    "    auc_list.append(auc)\n",
    "    \n",
    "    # 测试集进行预测，可以在这里添加代码\n",
    "    if 'df_test' in locals() and 'idx_test' in locals():\n",
    "        pred_test = model.predict(df_test, num_iteration=model.best_iteration)\n",
    "        pred_list.append(pred_test)\n",
    "\n",
    "# 计算平均AUC\n",
    "mean_auc = np.mean(auc_list)\n",
    "print(f'Mean AUC: {mean_auc:.4f}')\n",
    "\n",
    "# 保存预测结果\n",
    "if 'pred_list' in locals() and len(pred_list) > 0:\n",
    "    res = np.array(pred_list)\n",
    "    print(\"5折结果：\", res.shape)\n",
    "    r = res.mean(axis=0)\n",
    "    print('result shape:', r.shape)\n",
    "    result = pd.DataFrame()\n",
    "    result['idx'] = idx_test  # 假设idx_test是测试集的索引\n",
    "    result['y_pred'] = r\n",
    "    result.to_csv('lightgbm.csv', index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74e72f-ed96-4735-9f97-d56eca2c396f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fac2f0f-c2f6-47f1-b6a4-b54824dd48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_auc = np.mean(auc_list)\n",
    "print(\"mean auc:\", mean_auc)\n",
    "filepath = 'result/lgb_' + str(mean_auc) + '.csv'  # 线下平均分数\n",
    "# 转为array\n",
    "res = np.array(pred_list)\n",
    "print(\"5折结果：\", res.shape)\n",
    "\n",
    "# 最后结果，mean，max，min\n",
    "r = res.mean(axis=0)\n",
    "print('result shape:', r.shape)\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result['idx'] = idx_test\n",
    "result['y_pred'] = r\n",
    "result.to_csv('nplgbm.csv', index=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d68aef-e66c-4696-88d1-1fc2b5ad7079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
